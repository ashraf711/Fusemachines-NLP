{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Generation with n-grams\n",
    "## Learning Objective\n",
    "Here in this assignment, you will create a bigram model from the Brown corpus. You will use Laplace smoothing for bigrams and you will evaluate the perplexity of the model.\n",
    "\n",
    "In the last portion of the assignment, you will generate sentences from the bigram model.\n",
    "\n",
    "<b><div style=\"text-align: right\">[TOTAL POINTS: 10]</div></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Overview\n",
    "\n",
    "In this assignment you will be assigned to do the following tasks.\n",
    "\n",
    "* Preprocessig Dataset (lowercasing, removing punctuations, adding start and end tokens)\n",
    "* Adding unknown tokens\n",
    "* Creating n-grams and their corresponding counts\n",
    "* Creating Laplace Smoothing n-gram model\n",
    "* Calculating Perplexity of the model\n",
    "* Bonus (Sentence Generation with the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description:\n",
    "\n",
    "**Brown Corpus**\n",
    "\n",
    "The Brown Corpus is an electronic collection of text samples of American English in a varied genres. It was compiled by W. N. Francis and H. Kucera, Brown University.\n",
    "\n",
    "The corpus contains one million words of American English sampled from 15 different text categories. This corpus consists of 500 texts from different genres, each consisting of over 2000 words. The different text categories are as follows:\n",
    "\n",
    "    1. Report (44 texts)\n",
    "    2. Editorial (27 texts)\n",
    "    3. Reviews (17 texts)\n",
    "    4. Religion (17 texts)\n",
    "    5. Skill and Hobbies (36 texts)\n",
    "    6. Popular Lore (48 texts)\n",
    "    7. Belles-Lettres (75 texts)\n",
    "    8. Government (30 texts)\n",
    "    9. Learned (80 texts)\n",
    "    10. Fiction: General (29 texts)\n",
    "    11. Fiction: Mystery (24 texts)\n",
    "    12. Fiction: Science (6 texts)\n",
    "    13. Fiction: Adventure (29 texts)\n",
    "    14. Fiction: Romance (29 texts)\n",
    "    15. Humor (9 texts) \n",
    "\n",
    "*Source:* https://www1.essex.ac.uk/linguistics/external/clmt/w3c/corpus_ling/content/corpora/list/private/brown/brown.html \\\n",
    "*Author: W.N. Francis and H. Kucera, Brown University, Providence, RI*\n",
    "\n",
    "The Brown corpus is available in [NLTK corpora](http://www.nltk.org/nltk_data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/ashraf711/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "categories = brown.categories()\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the train set, you will use sentences from categories `'adventure', 'editorial', 'fiction', 'hobbies', 'humor', 'lore', 'mystery' 'reviews'`.\n",
    "\n",
    "And for the test set, you will use sentences from categories `'romance'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "[['Assembly', 'session', 'brought', 'much', 'good'], ['The', 'General', 'Assembly', ',', 'which', 'adjourns', 'today', ',', 'has', 'performed', 'in', 'an', 'atmosphere', 'of', 'crisis', 'and', 'struggle', 'from', 'the', 'day', 'it', 'convened', '.'], ['It', 'was', 'faced', 'immediately', 'with', 'a', 'showdown', 'on', 'the', 'schools', ',', 'an', 'issue', 'which', 'was', 'met', 'squarely', 'in', 'conjunction', 'with', 'the', 'governor', 'with', 'a', 'decision', 'not', 'to', 'risk', 'abandoning', 'public', 'education', '.'], ['There', 'followed', 'the', 'historic', 'appropriations', 'and', 'budget', 'fight', ',', 'in', 'which', 'the', 'General', 'Assembly', 'decided', 'to', 'tackle', 'executive', 'powers', '.'], ['The', 'final', 'decision', 'went', 'to', 'the', 'executive', 'but', 'a', 'way', 'has', 'been', 'opened', 'for', 'strengthening', 'budgeting', 'procedures', 'and', 'to', 'provide', 'legislators', 'information', 'they', 'need', '.'], ['Long-range', 'planning', 'of', 'programs', 'and', 'ways', 'to', 'finance', 'them', 'have', 'become', 'musts', 'if', 'the', 'state', 'in', 'the', 'next', 'few', 'years', 'is', 'to', 'avoid', 'crisis-to-crisis', 'government', '.'], ['This', 'session', ',', 'for', 'instance', ',', 'may', 'have', 'insured', 'a', 'financial', 'crisis', 'two', 'years', 'from', 'now', '.'], ['In', 'all', 'the', 'turmoil', ',', 'some', 'good', 'legislation', 'was', 'passed', '.'], ['Some', 'other', 'good', 'bills', 'were', 'lost', 'in', 'the', 'shuffle', 'and', 'await', 'future', 'action', '.'], ['Certainly', 'all', 'can', 'applaud', 'passage', 'of', 'an', 'auto', 'title', 'law', ',', 'the', 'school', 'bills', ',', 'the', 'increase', 'in', 'teacher', 'pensions', ',', 'the', 'ban', 'on', 'drag', 'racing', ',', 'acceptance', 'by', 'the', 'state', 'of', 'responsibility', 'for', 'maintenance', 'of', 'state', 'roads', 'in', 'municipalities', 'at', 'the', 'same', 'rate', 'as', 'outside', 'city', 'limits', ',', 'repeal', 'of', 'the', 'college', 'age', 'limit', 'law', 'and', 'the', 'road', 'maintenance', 'bond', 'issue', '.']]\n",
      "\n",
      "\n",
      "\n",
      "Test data: \n",
      "[['They', 'neither', 'liked', 'nor', 'disliked', 'the', 'Old', 'Man', '.'], ['To', 'them', 'he', 'could', 'have', 'been', 'the', 'broken', 'bell', 'in', 'the', 'church', 'tower', 'which', 'rang', 'before', 'and', 'after', 'Mass', ',', 'and', 'at', 'noon', ',', 'and', 'at', 'six', 'each', 'evening', '--', 'its', 'tone', ',', 'repetitive', ',', 'monotonous', ',', 'never', 'breaking', 'the', 'boredom', 'of', 'the', 'streets', '.'], ['The', 'Old', 'Man', 'was', 'unimportant', '.'], ['Yet', 'if', 'he', 'were', 'not', 'there', ',', 'they', 'would', 'have', 'missed', 'him', ',', 'as', 'they', 'would', 'have', 'missed', 'the', 'sounds', 'of', 'bees', 'buzzing', 'against', 'the', 'screen', 'door', 'in', 'early', 'June', ';', ';'], ['or', 'the', 'smell', 'of', 'thick', 'tomato', 'paste', '--', 'the', 'ripe', 'smell', 'that', 'was', 'both', 'sweet', 'and', 'sour', '--', 'rising', 'up', 'from', 'aluminum', 'trays', 'wrapped', 'in', 'fly-dotted', 'cheesecloth', '.'], ['Or', 'the', 'surging', 'whirling', 'sounds', 'of', 'bats', 'at', 'night', ',', 'when', 'their', 'black', 'bodies', 'dived', 'into', 'the', 'blackness', 'above', 'and', 'below', 'the', 'amber', 'street', 'lights', '.'], ['Or', 'the', 'bay', 'of', 'female', 'dogs', 'in', 'heat', '.'], ['They', 'never', 'called', 'him', 'by', 'name', ',', 'although', 'he', 'had', 'one', '.'], ['Filippo', 'Rossi', ',', \"that's\", 'what', 'he', 'was', 'called', 'in', 'the', 'old', 'country', ';', ';'], ['but', 'here', 'he', 'was', 'just', 'Signore', 'or', 'the', 'Old', 'Man', '.']]\n"
     ]
    }
   ],
   "source": [
    "train_lines = brown.sents(categories=['adventure', 'editorial', 'fiction', \n",
    "                                      'hobbies', 'humor', 'lore', 'mystery' 'reviews',\n",
    "                                     ])\n",
    "test_lines = brown.sents(categories=['romance'])\n",
    "\n",
    "print(f\"Training data: \\n{train_lines[:10]}\")\n",
    "print(\"\\n\\n\")\n",
    "print(f\"Test data: \\n{test_lines[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section you are provided `train_sentences` and `test_sentences` as list of lowercased sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sentences: \n",
      "['assembly session brought much good', 'the general assembly , which adjourns today , has performed in an atmosphere of crisis and struggle from the day it convened .', 'it was faced immediately with a showdown on the schools , an issue which was met squarely in conjunction with the governor with a decision not to risk abandoning public education .', 'there followed the historic appropriations and budget fight , in which the general assembly decided to tackle executive powers .', 'the final decision went to the executive but a way has been opened for strengthening budgeting procedures and to provide legislators information they need .', 'long-range planning of programs and ways to finance them have become musts if the state in the next few years is to avoid crisis-to-crisis government .', 'this session , for instance , may have insured a financial crisis two years from now .', 'in all the turmoil , some good legislation was passed .', 'some other good bills were lost in the shuffle and await future action .', 'certainly all can applaud passage of an auto title law , the school bills , the increase in teacher pensions , the ban on drag racing , acceptance by the state of responsibility for maintenance of state roads in municipalities at the same rate as outside city limits , repeal of the college age limit law and the road maintenance bond issue .']\n",
      "\n",
      "\n",
      "\n",
      "Test sentences: \n",
      "['they neither liked nor disliked the old man .', 'to them he could have been the broken bell in the church tower which rang before and after mass , and at noon , and at six each evening -- its tone , repetitive , monotonous , never breaking the boredom of the streets .', 'the old man was unimportant .', 'yet if he were not there , they would have missed him , as they would have missed the sounds of bees buzzing against the screen door in early june ; ;', 'or the smell of thick tomato paste -- the ripe smell that was both sweet and sour -- rising up from aluminum trays wrapped in fly-dotted cheesecloth .', 'or the surging whirling sounds of bats at night , when their black bodies dived into the blackness above and below the amber street lights .', 'or the bay of female dogs in heat .', 'they never called him by name , although he had one .', \"filippo rossi , that's what he was called in the old country ; ;\", 'but here he was just signore or the old man .']\n"
     ]
    }
   ],
   "source": [
    "train_sentences = [\" \".join(sent).lower() for sent in train_lines]\n",
    "test_sentences = [\" \".join(sent).lower() for sent in test_lines]\n",
    "\n",
    "print(f\"Training sentences: \\n{train_sentences[:10]}\")\n",
    "print(\"\\n\\n\")\n",
    "print(f\"Test sentences: \\n{test_sentences[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 : Remove punctuation and add start and end tokens.\n",
    "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
    "\n",
    "`train_sentences` and `test_sentences` contain lowercased list of sentences. However, they still contain punctuations such as `(\".\", \"?\", \",\", \"'\", \"-\")` etc. Your task is to remove those punctuations. Also, after removing the punctuations, your task is to add start `'<s>'` and end `'</s>'` tokens.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "* Remove punctuations\n",
    "* Add start and end tokens to each sentences\n",
    "* Return the list of sentences with removed puncuations and added start and end tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6755472e1ec6bec0d0aeef24dc8a175e",
     "grade": false,
     "grade_id": "cell-2585baf5b9165ee9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": [
     "Exercise-1"
    ]
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "SOS = \"<s> \"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "def basic_preprocess(sentences):\n",
    "    \"\"\"\n",
    "    Lowercase all words and remove punctuations.\n",
    "    And add start and end tokens.\n",
    "    \n",
    "    For example:\n",
    "    Args:\n",
    "        senetences(list) : ['this is first sentence .', 'this is second sentence .']\n",
    "    Returns:\n",
    "        sents(list): ['<s> this is first sentence </s>', '<s> this is second sentence </s>']\n",
    "    \"\"\"\n",
    "    \n",
    "    sents = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    sents = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Remove punctuations\n",
    "        sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        \n",
    "        # Add start and end tokens\n",
    "        sentence = SOS + sentence + EOS\n",
    "        \n",
    "        sents.append(sentence)\n",
    "    \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b0ce166d98222c6f130a75791b445c9",
     "grade": true,
     "grade_id": "cell-0dd5b5f562d07b2b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    },
    "tags": [
     "Exercise-1"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_sentences = basic_preprocess(train_sentences)\n",
    "processed_test_sentences = basic_preprocess(test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 : Replace words with count = 1 with '< UNK>' token and create word tokens\n",
    "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
    "\n",
    "`processed_train_sentences` and `processed_test_sentences` contain the processed sentences as a list. Your task is to check all the word tokens which appear only once in the corpus and replace them with `'<UNK>'` token. The function should return all of the sequence of words in the corpus in a single list.\n",
    "\n",
    "For example, if the sample input is: \n",
    "```\n",
    "['<s> this is first sentence </s>', '<s> this is second sentence </s>']\n",
    "```\n",
    "Here the words `'first'` and `'second'` appear only once in the corpus.\n",
    "The output should be:\n",
    "```\n",
    "['<s>', 'this', 'is', '<UNK>', 'sentence', '</s>', '<s>', 'this', 'is', '<UNK>', 'sentence', '</s>']\n",
    "```\n",
    "\n",
    "\n",
    "**Task:**\n",
    "\n",
    "*  Replace word counts=1 in the corpus with < UNK> token and create individual word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "41d6e6cc9755f7b71ab29b55ed2324a5",
     "grade": false,
     "grade_id": "cell-899c44a80a1cbafb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": [
     "Exercise-2"
    ]
   },
   "outputs": [],
   "source": [
    "UNK = \"<UNK>\"\n",
    "\n",
    "def generate_tokens(sentences):\n",
    "    \"\"\"\n",
    "    Takes a list of sentences with start and end tokens.\n",
    "    The function should replace the words which occur only once in the corpus with\n",
    "    '<UNK>' token and return the list of all tokens.\n",
    "    For example:\n",
    "    Args: \n",
    "        sentences(list): \n",
    "        ['<s> this is first sentence </s>', '<s> this is second sentence </s>']\n",
    "    \n",
    "    Returns: \n",
    "        tokens_with_unk(list): \n",
    "        ['<s>', 'this', 'is', '<UNK>', 'sentence', '</s>', '<s>', 'this', 'is', '<UNK>', 'sentence', '</s>']\n",
    "    \n",
    "    \"\"\"\n",
    "    tokens = \" \".join(sentences).split()\n",
    "    vocab = nltk.FreqDist(tokens)\n",
    "    \n",
    "    tokens_with_unk = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    tokens_with_unk = []\n",
    "    for token in tokens:\n",
    "        if vocab[token] == 1:\n",
    "            tokens_with_unk.append(UNK)\n",
    "        else:\n",
    "            tokens_with_unk.append(token)\n",
    "    \n",
    "    return tokens_with_unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c6ca720c915cb688ad9408ee040d347",
     "grade": true,
     "grade_id": "cell-9acfe5e3136bd33d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    },
    "tags": [
     "Exercise-2"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = generate_tokens(processed_train_sentences)\n",
    "test_tokens = generate_tokens(processed_train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 : Create n-grams and get their counts\n",
    "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
    "\n",
    "Now, it's time to create n-grams from the tokens generated from Exercise 2. Your task is to return unique n-grams with their corresponding counts.\n",
    "\n",
    "**Task:**\n",
    "* Create n-grams and return unique n-grams with their corresponding counts.\n",
    "\n",
    "Hint: `nltk.ngrams()` and `nltk.FreqDist()` functions may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "16042392ba42699ce956553a28b3415f",
     "grade": false,
     "grade_id": "cell-c10d71fd459b01c2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": [
     "Exercise-3"
    ]
   },
   "outputs": [],
   "source": [
    "def ngrams(tokens, n=2):\n",
    "    \"\"\"\n",
    "    Create n-grams and return unique n-grams with their corresponding counts.\n",
    "    \n",
    "    Args:\n",
    "        tokens (list): list of tokens\n",
    "        n(int) = 1 for unigram, 2 for bigram\n",
    "    \n",
    "    Returns:\n",
    "    n-grams(dict): dictionary of n-grams as a tuple and it's corresponding count. \n",
    "    \n",
    "    Example:\n",
    "        tokens = ['<s>', 'this', 'is', '<UNK>', 'sentence', '</s>', \n",
    "                '<s>', 'this', 'is', '<UNK>', 'sentence', '</s>']\n",
    "        For n = 1,\n",
    "        \n",
    "        n_grams:{\n",
    "                ('<s>',): 2, \n",
    "                ('this',): 2, \n",
    "                ('is',): 2, \n",
    "                ('<UNK>',): 2,\n",
    "                ('sentence',): 2,\n",
    "                ('</s>',): 2\n",
    "                }\n",
    "   \n",
    "        For n = 2,\n",
    "        \n",
    "        n_grams: {\n",
    "                ('<s>', 'this') : 2, \n",
    "                ('this', 'is') : 2, \n",
    "                ('is', '<UNK>') : 2,\n",
    "                ('<UNK>', 'sentence') : 2, \n",
    "                ('</s>' '<s>') : 1, \n",
    "                ('sentence', '</s>') : 2 \n",
    "                }\n",
    "    \"\"\"\n",
    "    ngram_dicts = None\n",
    "    # YOUR CODE HERE\n",
    "    ngram_dicts = nltk.FreqDist(nltk.ngrams(tokens, n))\n",
    "    return ngram_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a5d73bfc7b0640eb1375ccb3f297b2d9",
     "grade": true,
     "grade_id": "cell-8f1ba92468db5a67",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    },
    "tags": [
     "Exercise-3"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "\n",
    "bigram_dicts = ngrams(train_tokens, n) \n",
    "unigram_dicts = ngrams(train_tokens, n-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15106"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = nltk.FreqDist(train_tokens)\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 : Laplace Smoothing\n",
    "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
    "\n",
    "We know that the Laplace smoothing for bigram is given as:\n",
    "\n",
    "$$\n",
    "P_{Laplace}^{*}(w_n|w_{n-1}) = \\frac{\\text{count}(w_{n-1}w_n) + 1}{\\text{count}(w_{n-1}) + V}\n",
    "$$\n",
    "\n",
    "Here, $w_{n-1}$ is the previous word and $w_n$ is the present word of the bigram. Also, $V$ is the vocab size of the corpus.\n",
    "\n",
    "For eg:\n",
    "$$P_{Laplace}^{*}\\text{(\"great\"| \"the\")} = \\frac{\\text{count(\"the\", \"great\") + 1}}{\\text{count(\"the\")} + \\text{vocab_size}}$$\n",
    "\n",
    "**Task:**\n",
    "* Apply laplace smoothing for a bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "73f4f00e0019f6f8e3a6c1d25da3be5e",
     "grade": false,
     "grade_id": "cell-f4f953ddf2d6d675",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": [
     "Exercise-4"
    ]
   },
   "outputs": [],
   "source": [
    "def smoothed_bigram_prob(bigram, bigram_count, unigram_dicts, vocab_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        bigram (a tuple): a tuple of bigrams for ex: ('the', 'great')\n",
    "        bigram_count(int): count of bigram\n",
    "        unigram_dicts: dictionary containing unigrams and their corresponding counts\n",
    "        vocab_size: vocab size of the corpus\n",
    "    \n",
    "    Returns:\n",
    "        smoothed_prob(float): Smoothed probability of the bigram.\n",
    "    \"\"\"    \n",
    "    \n",
    "    unigram = None\n",
    "    unigram_count = None\n",
    "    smoothed_prob = None\n",
    "    # YOUR CODE HERE\n",
    "    unigram = bigram[0]\n",
    "    unigram_count = unigram_dicts[unigram] if unigram in unigram_dicts else 0\n",
    "    smoothed_prob = (bigram_count + 1) / (unigram_count + vocab_size)\n",
    "    return smoothed_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b7bc3adf2b877eeca74af609a2026f3e",
     "grade": true,
     "grade_id": "cell-8229ab29523521aa",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    },
    "tags": [
     "Exercise-4"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(bigram_dicts):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        bigram_dicts (dict): dictionary items containing bigram tuple and their corresponding count.\n",
    "    \n",
    "    Returns:\n",
    "        (dict) : dictionary items containing bigram tuple and thier smoothed probability.\n",
    "    \"\"\"\n",
    "    return { n_gram: smoothed_bigram_prob(n_gram, count, unigram_dicts, vocab_size) \\\n",
    "            for n_gram, count in bigram_dicts.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('</s>', '<s>'), 1.4291672183238449),\n",
       " (('of', 'the'), 0.20190652720773203),\n",
       " (('<s>', 'the'), 0.1616576194889448),\n",
       " (('in', 'the'), 0.135509069244009),\n",
       " (('the', '<UNK>'), 0.10035747385144976),\n",
       " (('<UNK>', '</s>'), 0.0971799285052297),\n",
       " (('<s>', 'he'), 0.0904938435058917),\n",
       " (('to', 'the'), 0.0807626108830928),\n",
       " (('on', 'the'), 0.06361710578578049),\n",
       " (('<UNK>', 'and'), 0.05573944128160996),\n",
       " (('<UNK>', '<UNK>'), 0.054349265192638684),\n",
       " (('<s>', 'it'), 0.05209850390573282),\n",
       " (('and', 'the'), 0.05004633920296571),\n",
       " (('a', '<UNK>'), 0.05004633920296571),\n",
       " (('<s>', 'i'), 0.04739838474778234),\n",
       " (('and', '<UNK>'), 0.04554481662915398),\n",
       " (('at', 'the'), 0.042102475837415596),\n",
       " (('for', 'the'), 0.04137428836224017),\n",
       " (('<UNK>', 'of'), 0.039454521382232224),\n",
       " (('<s>', 'but'), 0.03819674301602012)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smoothing(bigram_dicts)\n",
    "sorted(model.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 : Calculate perplexity.\n",
    "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
    "\n",
    "We know the perplexity of the test set for bigram is given as:\n",
    "$$\n",
    "PP(S) = \\sqrt[N]{\\frac{1}{\\prod \\limits_{i=1}^{N} P(w_i | w_{i-1})}}    \\tag{1}\n",
    "$$\n",
    "\n",
    "i.e\n",
    "$$ \n",
    "PP(S) = ({\\prod \\limits_{i=1}^{N} P(w_i | w_{i-1})})^{\\frac{-1}{N}} \\tag{2}\n",
    "$$\n",
    "\n",
    "Take log on both sides:\n",
    "$$\n",
    "log(PP(S)) = {-\\frac{1}{N}} \\sum \\limits_{i=1}^{N}{log(P(w_i | w_{i-1}))} \\tag{3}\n",
    "$$\n",
    "\n",
    "\n",
    "So, the $PP(S)$ is exponential of sum of log probabilities, normalized by the number of tokens in the test set. \\\n",
    "i.e.\n",
    "$$\n",
    "PP(S) = \\exp(-{\\frac{1}{N}} \\sum \\limits_{i=1}^{N}{log(P(w_i | w_{i-1}))})  \\tag{4}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**Task:**\n",
    "* You are given the probabilities of the test set in a list. Calculate the perplexity of the test set, using equation (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [[1,1], [1, 0], [0, 1], [0, 0]]\n",
    "\n",
    "def convert_oov(ngram):\n",
    "    \"\"\"Converts, if necessary, a given n-gram to one which is known by the model.\n",
    "    Args:\n",
    "        ngram (tuple): a bigram tuple. for ex: (\"the\", \"great\")\n",
    "    Returns:\n",
    "        The n-gram with <UNK> tokens in certain positions such that the model\n",
    "        contains an entry for it.\n",
    "\n",
    "    \"\"\"\n",
    "    mask = lambda ngram, bitmask: tuple((token if flag == 1 else \"<UNK>\" for token,flag in zip(ngram, bitmask)))\n",
    "\n",
    "    ngram = (ngram,) if type(ngram) is str else ngram\n",
    "    for possible_known in [mask(ngram, bitmask) for bitmask in masks]:\n",
    "        if possible_known in model:\n",
    "            return possible_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ngrams = nltk.ngrams(test_tokens, 2)\n",
    "N = len(test_tokens)\n",
    "known_ngrams  = (convert_oov(ngram) for ngram in test_ngrams)\n",
    "probs = [model[ngram] for ngram in known_ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "472e1cd50aa1a0c407fa18db7f415736",
     "grade": false,
     "grade_id": "cell-440b8941bad5499b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": [
     "Exercise-5"
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def perplexity(prob, N):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        probs(list): list of test probabilities.\n",
    "        N(int): Number of tokens in the test set.\n",
    "    \n",
    "    Returns:\n",
    "        perplexity(float): Perplexity of the model in the test set.\n",
    "    \"\"\"\n",
    "    perplexity = None\n",
    "    # YOUR CODE HERE\n",
    "    avg_log_prob = sum(math.log(p) for p in prob) / N\n",
    "    perplexity = math.exp(-avg_log_prob)\n",
    "    return perplexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of the model is: 1007.8564092839028\n"
     ]
    }
   ],
   "source": [
    "pps = perplexity(probs, N)\n",
    "print(f\"Perplexity of the model is: {pps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1a5dec514c21b11b5138af17bfd6b71",
     "grade": true,
     "grade_id": "cell-0f0fa656aab6075f",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "tags": [
     "Exercise-5"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Generation with n-grams\n",
    "Now that our bigram model is ready, let's generate some sample sentences from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import random\n",
    "def best_candidate(prev, i, without=[]):\n",
    "    \"\"\"Choose the most likely next token given the previous (n-1) tokens.\n",
    "    Args:\n",
    "        prev (tuple of str): the previous n-1 tokens of the sentence.\n",
    "        i (int): which candidate to select if not the most probable one.\n",
    "        without (list of str): tokens to exclude from the candidates list.\n",
    "    Returns:\n",
    "        A tuple with the next most probable token and its corresponding probability.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    blacklist  = [\"<UNK>\"] + without\n",
    "    candidates = ((ngram[-1], prob) for ngram, prob in model.items() if ngram[:-1]==prev)\n",
    "    candidates = filter(lambda candidate: candidate[0] not in blacklist, candidates)\n",
    "    candidates = sorted(candidates, key=lambda candidate: candidate[1], reverse=True)\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        return (\"</s>\", 1)\n",
    "    else:\n",
    "        candidate_index = int((random.randint(0, len(candidates)))/2)\n",
    "        return candidates[candidate_index if prev != () and prev[-1] != \"<s>\" else i]\n",
    "    \n",
    "def generate_sentences(num, min_len=12, max_len=24): \n",
    "    \"\"\"Generate random sentences using the language model.\n",
    "    Args:\n",
    "        num (int): the number of sentences to generate.\n",
    "        min_len (int): minimum allowed sentence length.\n",
    "        max_len (int): maximum allowed sentence length.\n",
    "    Yields:\n",
    "        A tuple with the generated sentence and the combined probability\n",
    "        (in log-space) of all of its n-grams.\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(num):\n",
    "        sent, prob = [\"<s>\"], 1\n",
    "        while sent[-1] != \"</s>\":\n",
    "            prev = tuple(sent[-(1):])\n",
    "            blacklist = sent + ([\"</s>\"] if len(sent) < min_len else [])\n",
    "            next_token, next_prob = best_candidate(prev, i, without=blacklist)\n",
    "            sent.append(next_token)\n",
    "            prob *= next_prob\n",
    "            \n",
    "            if len(sent) >= max_len:\n",
    "                sent.append(\"</s>\")\n",
    "\n",
    "        yield ' '.join(sent), -1/math.log(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sentences...\n",
      "<s> the gulf telephone company expects of help them apparent that unless we all volumes one down for ten seconds greg felt about assassination </s> (0.00528)\n",
      "<s> he spoke briefly at first penetration instead a good plain american article jan 18 long hot days only place patterns that master calvin </s> (0.00536)\n",
      "<s> it dislikes or hair like those depending on duty as thomas h whites themselves during all seasons its fortunes in china which suggests </s> (0.00517)\n",
      "<s> i guess we stand position for orthodontic treatment are hauled inboard or less happy all stores in continental soldiers monument to khrushchev kennedy </s> (0.00528)\n",
      "<s> but serene mrs lattimer and everywhere is salt pepper celery 14 thickness in japan </s> (0.00806)\n",
      "<s> in protecting american press should get inside his offer exceptional design head where hed not digging nights till the essence a bag of </s> (0.00517)\n",
      "<s> a pint of civil law to hit and machinery by studying interviews they prepare less respect boats in carolina traders engaged as warfare </s> (0.00518)\n",
      "<s> and my favorite throughout your front often assumed his destiny in many lives near petersburg informed her life for different color which passed </s> (0.00524)\n",
      "<s> they rode off a speech to whether cubic centimeters cc making promises there might get along </s> (0.00730)\n",
      "<s> she visited him like these colleges schedule what better place pattern c atkinson and reverse the brown hair of mistakes </s> (0.00570)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating sentences...\")\n",
    "for sentence, prob in generate_sentences(num = 10):\n",
    "    print(\"{} ({:.5f})\".format(sentence, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in this assignment, we build a bigram model using Laplace smoothing techniques and we calculated perplexity of the model in the test set.\n",
    "\n",
    "Then, we generated some sample sentences from the bigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations for successfully completing the assignment**.\n",
    "\n",
    "Good Luck going forward with the course. \n",
    "See you in the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
